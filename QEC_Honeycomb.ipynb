{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stim\n",
        "!pip install pymatching\n",
        "!pip install networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cirp_oqaNLSb",
        "outputId": "ca2075f9-e6b6-481d-8a1e-172a447def9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stim\n",
            "  Downloading stim-1.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from stim) (2.0.2)\n",
            "Downloading stim-1.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stim\n",
            "Successfully installed stim-1.15.0\n",
            "Collecting pymatching\n",
            "  Downloading pymatching-2.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pymatching) (1.16.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pymatching) (2.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pymatching) (3.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pymatching) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pymatching) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->pymatching) (1.17.0)\n",
            "Downloading pymatching-2.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.1/626.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymatching\n",
            "Successfully installed pymatching-2.3.1\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZelWyoAlNGPB",
        "outputId": "59b31c18-092c-45b5-cdb9-05054ae03519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diameter_factors [1, 2]\n",
            "probabilities [0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
            "num_shots 10000\n",
            "                         physical error rate 0.01:here\n",
            "here\n",
            "\n",
            "                        physical error rate 0.015:here\n",
            "here\n",
            "\n",
            "                         physical error rate 0.02:here\n",
            "here\n",
            "\n",
            "                        physical error rate 0.025:here\n",
            "here\n",
            "\n",
            "                         physical error rate 0.03:here\n",
            "here\n",
            "\n",
            "                        physical error rate 0.035:here\n",
            "here\n",
            "\n",
            "                         physical error rate 0.04:here\n",
            "here\n",
            "\n",
            "                        physical error rate 0.045:here\n",
            "here\n",
            "\n",
            "                         physical error rate 0.05:here\n",
            "here\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pathlib\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, List, Dict, Any, Set, FrozenSet, Iterable, Tuple\n",
        "import math\n",
        "import pymatching\n",
        "import networkx as nx\n",
        "import stim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define some data for working with the three edge orientations.\n",
        "@dataclass\n",
        "class EdgeType:\n",
        "    pauli: str\n",
        "    hex_to_hex_delta: complex\n",
        "    hex_to_qubit_delta: complex\n",
        "EDGE_TYPES = [\n",
        "    EdgeType(pauli=\"X\", hex_to_hex_delta=2 - 3j, hex_to_qubit_delta=1 - 1j),\n",
        "    EdgeType(pauli=\"Y\", hex_to_hex_delta=2 + 3j, hex_to_qubit_delta=1 + 1j),\n",
        "    EdgeType(pauli=\"Z\", hex_to_hex_delta=4, hex_to_qubit_delta=1),\n",
        "]\n",
        "EDGES_AROUND_HEX: List[Tuple[complex, complex]] = [\n",
        "    (-1 - 1j, +1 - 1j),\n",
        "    (+1 - 1j, +1),\n",
        "    (+1, +1 + 1j),\n",
        "    (+1 + 1j, -1 + 1j),\n",
        "    (-1 + 1j, -1),\n",
        "    (-1, -1 - 1j),\n",
        "]\n",
        "\n",
        "\n",
        "def generate_circuit_cycle(*,\n",
        "                           q2i: Dict[complex, int],\n",
        "                           before_parity_measure_2q_depolarization: float,\n",
        "                           before_round_1q_depolarization: float,\n",
        "                           before_cycle_1q_depolarization: float,\n",
        "                           hex_centers: Dict[complex, int],\n",
        "                           distance: int,\n",
        "                           detectors: bool) -> stim.Circuit:\n",
        "    round_circuits = []\n",
        "    measurement_times: Dict[FrozenSet[int], int] = {}\n",
        "    current_time = 0\n",
        "    measurements_per_round: int\n",
        "    for r in range(3):\n",
        "\n",
        "        relevant_hexes = [h for h, category in hex_centers.items() if category == r]\n",
        "\n",
        "        # Find the edges between the relevant hexes, grouped as X/Y/Z.\n",
        "        edge_groups: Dict[str, List[FrozenSet[complex]]] = {\"X\": [], \"Y\": [], \"Z\": []}\n",
        "        for h in relevant_hexes:\n",
        "            for edge_type in EDGE_TYPES:\n",
        "                q1 = torus(h + edge_type.hex_to_qubit_delta, distance=distance)\n",
        "                q2 = torus(h + edge_type.hex_to_hex_delta - edge_type.hex_to_qubit_delta, distance=distance)\n",
        "                edge_groups[edge_type.pauli].append(frozenset([q1, q2]))\n",
        "        x_qubits = [q2i[q] for pair in edge_groups[\"X\"] for q in sorted_complex(pair)]\n",
        "        y_qubits = [q2i[q] for pair in edge_groups[\"Y\"] for q in sorted_complex(pair)]\n",
        "\n",
        "        circuit = stim.Circuit()\n",
        "        if before_round_1q_depolarization > 0:\n",
        "            circuit.append_operation(\"DEPOLARIZE1\", sorted(q2i.values()), before_round_1q_depolarization)\n",
        "\n",
        "        # Make all the parity operations Z basis parities.\n",
        "        circuit.append_operation(\"H\", x_qubits)\n",
        "        circuit.append_operation(\"H_YZ\", y_qubits)\n",
        "\n",
        "        # Turn parity observables into single qubit observables.\n",
        "        pair_targets = [\n",
        "            q2i[q]\n",
        "            for group in edge_groups.values()\n",
        "            for pair in group\n",
        "            for q in sorted_complex(pair)\n",
        "        ]\n",
        "        if before_parity_measure_2q_depolarization > 0:\n",
        "            circuit.append_operation(\"DEPOLARIZE2\", pair_targets, before_parity_measure_2q_depolarization)\n",
        "        circuit.append_operation(\"CNOT\", pair_targets)\n",
        "\n",
        "        # Measure\n",
        "        for k in range(0, len(pair_targets), 2):\n",
        "            edge_key = frozenset([pair_targets[k], pair_targets[k + 1]])\n",
        "            measurement_times[edge_key] = current_time\n",
        "            current_time += 1\n",
        "        circuit.append_operation(\"M\", pair_targets[1::2])\n",
        "\n",
        "        # Restore qubit bases.\n",
        "        circuit.append_operation(\"CNOT\", pair_targets)\n",
        "        circuit.append_operation(\"H_YZ\", y_qubits)\n",
        "        circuit.append_operation(\"H\", x_qubits)\n",
        "\n",
        "        # Multiply relevant measurements into the observable.\n",
        "        included_measurements = []\n",
        "        for group in edge_groups.values():\n",
        "            for pair in group:\n",
        "                a, b = pair\n",
        "                if a.real == b.real == 1:\n",
        "                    edge_key = frozenset([q2i[a], q2i[b]])\n",
        "                    included_measurements.append(stim.target_rec(measurement_times[edge_key] - current_time))\n",
        "        circuit.append_operation(\"OBSERVABLE_INCLUDE\", included_measurements, 0)\n",
        "\n",
        "        round_circuits.append(circuit)\n",
        "    measurements_per_cycle = current_time\n",
        "    measurements_per_round = measurements_per_cycle // 3\n",
        "\n",
        "    # Determine which sets of measurements to compare in order to get detection events in the bulk.\n",
        "    if detectors:\n",
        "        for r in range(3):\n",
        "            circuit = stim.Circuit()\n",
        "            relevant_hexes = [h for h, category in hex_centers.items() if category == (r + 1) % 3]\n",
        "            end_time = (r + 1) * measurements_per_round\n",
        "            for h in relevant_hexes:\n",
        "                record_targets = []\n",
        "                for a, b in EDGES_AROUND_HEX:\n",
        "                    q1 = torus(h + a, distance=distance)\n",
        "                    q2 = torus(h + b, distance=distance)\n",
        "                    edge_key = frozenset([q2i[q1], q2i[q2]])\n",
        "                    relative_index = (measurement_times[edge_key] - end_time) % measurements_per_cycle - measurements_per_cycle\n",
        "                    record_targets.append(stim.target_rec(relative_index))\n",
        "                    record_targets.append(stim.target_rec(relative_index - measurements_per_cycle))\n",
        "                circuit.append_operation(\"DETECTOR\", record_targets, [h.real, h.imag, 0])\n",
        "            circuit.append_operation(\"SHIFT_COORDS\", [], [0, 0, 1])\n",
        "            round_circuits[r] += circuit\n",
        "\n",
        "    full_circuit = stim.Circuit()\n",
        "    if before_cycle_1q_depolarization > 0:\n",
        "        full_circuit.append_operation(\"DEPOLARIZE1\", sorted(q2i.values()), before_cycle_1q_depolarization)\n",
        "    full_circuit += round_circuits[0] + round_circuits[1] + round_circuits[2]\n",
        "    return full_circuit\n",
        "\n",
        "\n",
        "def generate_circuit(distance: int, cycles: int,\n",
        "                     before_parity_measure_2q_depolarization: float,\n",
        "                     before_round_1q_depolarization: float,\n",
        "                     before_cycle_1q_depolarization: float,\n",
        "                     start_of_all_noisy_cycles_1q_depolarization: float,\n",
        "                     ) -> stim.Circuit:\n",
        "\n",
        "    # Generate and categorize the hexes defining the circuit.\n",
        "    hex_centers: Dict[complex, int] = {}\n",
        "    for row in range(3 * distance):\n",
        "        for col in range(2 * distance):\n",
        "            center = row * 2j + 2 * col - 1j * (col % 2)\n",
        "            category = (-row - col % 2) % 3\n",
        "            hex_centers[torus(center, distance=distance)] = category\n",
        "\n",
        "    # Find all the qubit positions around the hexes.\n",
        "    qubit_coordinates: Set[complex] = set()\n",
        "    for h in hex_centers:\n",
        "        for edge_type in EDGE_TYPES:\n",
        "            for sign in [-1, +1]:\n",
        "                q = h + edge_type.hex_to_qubit_delta * sign\n",
        "                qubit_coordinates.add(torus(q, distance=distance))\n",
        "\n",
        "    # Assign integer indices to the qubit positions.\n",
        "    q2i: Dict[complex, int] = {q: i for i, q in enumerate(sorted_complex(qubit_coordinates))}\n",
        "\n",
        "    # Generate a circuit performing the parity measurements that are part of each round.\n",
        "    # Also keep track of the exact order the measurements occur in.\n",
        "    round_circuit_no_noise_no_detectors = generate_circuit_cycle(\n",
        "        q2i=q2i,\n",
        "        before_parity_measure_2q_depolarization=0,\n",
        "        before_round_1q_depolarization=0,\n",
        "        before_cycle_1q_depolarization=0,\n",
        "        hex_centers=hex_centers,\n",
        "        distance=distance,\n",
        "        detectors=False,\n",
        "    )\n",
        "    round_circuit_no_noise_yes_detectors = generate_circuit_cycle(\n",
        "        q2i=q2i,\n",
        "        before_parity_measure_2q_depolarization=0,\n",
        "        before_round_1q_depolarization=0,\n",
        "        before_cycle_1q_depolarization=0,\n",
        "        hex_centers=hex_centers,\n",
        "        distance=distance,\n",
        "        detectors=True,\n",
        "    )\n",
        "    round_circuit_yes_noise_yes_detectors = generate_circuit_cycle(\n",
        "        q2i=q2i,\n",
        "        before_parity_measure_2q_depolarization=before_parity_measure_2q_depolarization,\n",
        "        before_round_1q_depolarization=before_round_1q_depolarization,\n",
        "        before_cycle_1q_depolarization=before_cycle_1q_depolarization,\n",
        "        hex_centers=hex_centers,\n",
        "        distance=distance,\n",
        "        detectors=True,\n",
        "    )\n",
        "\n",
        "    # Put together the pieces to get a correctable noisy circuit with noiseless time padding\n",
        "    # (since the time boundaries are not implemented yet).\n",
        "    full_circuit = stim.Circuit()\n",
        "    for q, i in q2i.items():\n",
        "        full_circuit.append_operation(\"QUBIT_COORDS\", [i], [q.real, q.imag])\n",
        "\n",
        "    # Initialize data qubits along logical observable column into correct basis for observable to be deterministic.\n",
        "    qubits_along_column = sorted([q for q in qubit_coordinates if q.real == 1], key=lambda v: v.imag)\n",
        "    initial_bases_along_column = \"ZY_ZX_\" * distance\n",
        "    x_initialized = [q2i[q] for q, b in zip(qubits_along_column, initial_bases_along_column) if b == \"X\"]\n",
        "    y_initialized = [q2i[q] for q, b in zip(qubits_along_column, initial_bases_along_column) if b == \"Y\"]\n",
        "    full_circuit.append_operation(\"H\", x_initialized)\n",
        "    full_circuit.append_operation(\"H_YZ\", y_initialized)\n",
        "\n",
        "    full_circuit += (\n",
        "            round_circuit_no_noise_no_detectors * 2\n",
        "            + round_circuit_no_noise_yes_detectors * 2\n",
        "    )\n",
        "    if start_of_all_noisy_cycles_1q_depolarization > 0:\n",
        "        full_circuit.append_operation(\"DEPOLARIZE1\",\n",
        "                                      sorted(q2i.values()),\n",
        "                                      start_of_all_noisy_cycles_1q_depolarization)\n",
        "    full_circuit += (\n",
        "            round_circuit_yes_noise_yes_detectors * cycles\n",
        "            + round_circuit_no_noise_yes_detectors * 2\n",
        "            + round_circuit_no_noise_no_detectors * 2\n",
        "    )\n",
        "\n",
        "    # Finish circuit with data measurements.\n",
        "    qubit_coords_to_measure = [q for q, b in zip(qubits_along_column, initial_bases_along_column) if b != \"_\"]\n",
        "    qubit_indices_to_measure= [q2i[q] for q in qubit_coords_to_measure]\n",
        "    order = {q: i for i, q in enumerate(qubit_indices_to_measure)}\n",
        "    assert cycles % 2 == 0\n",
        "    full_circuit.append_operation(\"H_YZ\", y_initialized)\n",
        "    full_circuit.append_operation(\"H\", x_initialized)\n",
        "    full_circuit.append_operation(\"M\", qubit_indices_to_measure)\n",
        "\n",
        "    full_circuit.append_operation(\"OBSERVABLE_INCLUDE\",\n",
        "                                  [stim.target_rec(i - len(qubit_indices_to_measure)) for i in order.values()],\n",
        "                                  0)\n",
        "\n",
        "    return full_circuit\n",
        "\n",
        "\n",
        "def print_2d(values: Dict[complex, Any]):\n",
        "    assert all(v.real == int(v.real) for v in values)\n",
        "    assert all(v.imag == int(v.imag) for v in values)\n",
        "    assert all(v.real >= 0 and v.imag >= 0 for v in values)\n",
        "    w = int(max((v.real for v in values), default=0) + 1)\n",
        "    h = int(max((v.imag for v in values), default=0) + 1)\n",
        "    s = \"\"\n",
        "    for y in range(h):\n",
        "        for x in range(w):\n",
        "            s += str(values.get(x + y*1j, \"_\"))\n",
        "        s += \"\\n\"\n",
        "    print(s)\n",
        "\n",
        "\n",
        "def torus(c: complex, *, distance: int) -> complex:\n",
        "    r = c.real % (distance * 4)\n",
        "    i = c.imag % (distance * 6)\n",
        "    return r + i*1j\n",
        "\n",
        "\n",
        "def sorted_complex(xs: Iterable[complex]) -> List[complex]:\n",
        "    return sorted(xs, key=lambda v: (v.real, v.imag))\n",
        "\n",
        "\n",
        "def run_shots_correct_errors_return_num_correct(circuit: stim.Circuit, num_shots: int):\n",
        "    \"\"\"Collect statistics on how often logical errors occur when correcting using detections.\"\"\"\n",
        "    e = circuit.detector_error_model()\n",
        "    m = detector_error_model_to_matching(e)\n",
        "\n",
        "    print(\"here\")\n",
        "    print(f\"e: {e}\")\n",
        "    return\n",
        "\n",
        "    t0 = time.monotonic()\n",
        "    detector_samples = circuit.compile_detector_sampler().sample(num_shots, append_observables=True)\n",
        "    t1 = time.monotonic()\n",
        "\n",
        "    num_correct = 0\n",
        "    for sample in detector_samples:\n",
        "        actual_observable = sample[-1]\n",
        "        detectors_only = sample.copy()\n",
        "        detectors_only[-1] = 0\n",
        "        predicted_observable = m.decode(detectors_only)[0]\n",
        "        num_correct += actual_observable == predicted_observable\n",
        "    t2 = time.monotonic()\n",
        "\n",
        "    # decode_time = t2 - t1\n",
        "    # sample_time = t1 - t0\n",
        "    # print(\"decode\", decode_time, \"sample\", sample_time)\n",
        "\n",
        "    return num_correct\n",
        "\n",
        "\n",
        "def detector_error_model_to_matching(model: stim.DetectorErrorModel) -> pymatching.Matching:\n",
        "    \"\"\"Convert stim error model into a pymatching graph.\"\"\"\n",
        "    det_offset = 0\n",
        "\n",
        "    def _iter_model(m: stim.DetectorErrorModel, reps: int, callback: Callable[[float, List[int], List[int]], None]):\n",
        "        nonlocal det_offset\n",
        "        for _ in range(reps):\n",
        "            for instruction in m:\n",
        "                if isinstance(instruction, stim.DemRepeatBlock):\n",
        "                    _iter_model(instruction.body_copy(), instruction.repeat_count, callback)\n",
        "                elif isinstance(instruction, stim.DemInstruction):\n",
        "                    if instruction.type == \"error\":\n",
        "                        dets = []\n",
        "                        frames = []\n",
        "                        for t in instruction.targets_copy():\n",
        "                            v = str(t)\n",
        "                            if v.startswith(\"D\"):\n",
        "                                dets.append(int(v[1:]) + det_offset)\n",
        "                            elif v.startswith(\"L\"):\n",
        "                                frames.append(int(v[1:]))\n",
        "                            else:\n",
        "                                raise NotImplementedError()\n",
        "                        p = instruction.args_copy()[0]\n",
        "                        callback(p, dets, frames)\n",
        "                    elif instruction.type == \"shift_detectors\":\n",
        "                        det_offset += instruction.targets_copy()[0]\n",
        "                    elif instruction.type == \"detector\":\n",
        "                        pass\n",
        "                    elif instruction.type == \"logical_observable\":\n",
        "                        pass\n",
        "                    else:\n",
        "                        raise NotImplementedError()\n",
        "                else:\n",
        "                    raise NotImplementedError()\n",
        "\n",
        "    g = nx.Graph()\n",
        "    num_detectors = model.num_detectors\n",
        "    for k in range(num_detectors):\n",
        "        g.add_node(k)\n",
        "    g.add_node(num_detectors, is_boundary=True)\n",
        "    g.add_node(num_detectors + 1)\n",
        "    for k in range(num_detectors + 1):\n",
        "        g.add_edge(k, num_detectors + 1, weight=9999999999)\n",
        "\n",
        "    def handle_error(p: float, dets: List[int], frame_changes: List[int]):\n",
        "        if p == 0:\n",
        "            return\n",
        "        if len(dets) == 1:\n",
        "            dets.append(num_detectors)\n",
        "        if len(dets) != 2:\n",
        "            return  # Just ignore correlated error mechanisms (e.g. Y errors / XX errors)\n",
        "        g.add_edge(*dets, weight=-math.log(p), qubit_id=frame_changes)\n",
        "\n",
        "    _iter_model(model, 1, handle_error)\n",
        "\n",
        "    return pymatching.Matching(g)\n",
        "\n",
        "\n",
        "def sample_error_rates(*,\n",
        "                       probabilities: List[float],\n",
        "                       diameter_factor: List[int],\n",
        "                       append: bool,\n",
        "                       path: str,\n",
        "                       shots: int,\n",
        "                       noisy_cycles: int,\n",
        "                       before_parity_measure_2q_depolarization_factor: float,\n",
        "                       before_round_1q_depolarization_factor: float,\n",
        "                       before_cycle_1q_depolarization_factor: float,\n",
        "                       start_of_all_noisy_cycles_1q_depolarization_factor: float):\n",
        "    if not pathlib.Path(path).exists():\n",
        "        append = False\n",
        "    with open(path, \"a\" if append else \"w\") as f:\n",
        "        if not append:\n",
        "            print(\"distance,physical_error_rate,num_shots,num_correct\", file=f)\n",
        "        print(\"diameter_factors\", diameter_factor)\n",
        "        print(\"probabilities\", probabilities)\n",
        "        print(\"num_shots\", shots)\n",
        "        for p in probabilities:\n",
        "            s = f\"physical error rate {p}:\"\n",
        "            s = s.rjust(50)\n",
        "            print(s , end=\"\")\n",
        "            for d in diameter_factor:\n",
        "                circuit = generate_circuit(\n",
        "                    distance=d,\n",
        "                    cycles=noisy_cycles,\n",
        "                    before_cycle_1q_depolarization=before_cycle_1q_depolarization_factor*p,\n",
        "                    before_round_1q_depolarization=before_round_1q_depolarization_factor*p,\n",
        "                    before_parity_measure_2q_depolarization=before_parity_measure_2q_depolarization_factor*p,\n",
        "                    start_of_all_noisy_cycles_1q_depolarization=start_of_all_noisy_cycles_1q_depolarization_factor*p,\n",
        "                )\n",
        "                num_correct = run_shots_correct_errors_return_num_correct(\n",
        "                    num_shots=shots,\n",
        "                    circuit=circuit,\n",
        "                )\n",
        "                # print(f\" {shots - num_correct}\", end=\"\")\n",
        "                # print(f\"{d},{p},{shots},{num_correct}\", file=f, flush=True)\n",
        "            print()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DistanceExperimentData:\n",
        "    num_shots: int = 0\n",
        "    num_correct: int = 0\n",
        "\n",
        "    @property\n",
        "    def logical_error_rate(self) -> float:\n",
        "        return (self.num_shots - self.num_correct) / self.num_shots\n",
        "\n",
        "\n",
        "def round_adjustment(error_rate: float, rounds: int) -> float:\n",
        "    randomize_rate = min(1, 2*error_rate)\n",
        "    round_randomize_rate = 1 - (1 - randomize_rate)**(1 / rounds)\n",
        "    round_error_rate = round_randomize_rate / 2\n",
        "    return round_error_rate\n",
        "\n",
        "\n",
        "def plot_data(path: str, title: str, rounds_per_shot: int):\n",
        "    distance_to_noise_to_results: Dict[int, Dict[float, DistanceExperimentData]] = {}\n",
        "    with open(path, \"r\") as f:\n",
        "        for row in csv.DictReader(f):\n",
        "            distance = int(row[\"distance\"])\n",
        "            physical_error_rate = float(row[\"physical_error_rate\"])\n",
        "            d1 = distance_to_noise_to_results.setdefault(distance, {})\n",
        "            d2 = d1.setdefault(physical_error_rate, DistanceExperimentData())\n",
        "            d2.num_shots += int(row[\"num_shots\"])\n",
        "            d2.num_correct += int(row[\"num_correct\"])\n",
        "\n",
        "    markers = \"_ov*sp^<>12348PhH+xXDd|\"\n",
        "    for distance in sorted(distance_to_noise_to_results.keys()):\n",
        "        group = distance_to_noise_to_results[distance]\n",
        "        xs = []\n",
        "        ys = []\n",
        "        for physical_error_rate in sorted(group.keys()):\n",
        "            data = group[physical_error_rate]\n",
        "            xs.append(physical_error_rate)\n",
        "            ys.append(round_adjustment(data.logical_error_rate, rounds=rounds_per_shot))\n",
        "        plt.plot(xs, ys, label=f\"diameter_scale_factor={distance}\", marker=markers[distance])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.loglog()\n",
        "\n",
        "    def f(p):\n",
        "        if abs(p * 100 - int(p * 100)) < 1e-5:\n",
        "            return str(int(p * 100)) + \"%\"\n",
        "        r = f\"{p:.3%}\"\n",
        "        while r and r[-2:] == \"0%\":\n",
        "            r = r[:-2] + \"%\"\n",
        "        return r\n",
        "    ticks_y = [k*10**-p for k in range(1, 10) for p in range(1, 5) if k*10**-p <= 0.5]\n",
        "    ticks_x = [k*10**-p for k in range(1, 10) for p in range(1, 5) if k*10**-p <= 0.5]\n",
        "    ticks_x.extend([p/100 for p in range(12, 20, 2)])\n",
        "    plt.xticks([x for x in ticks_x], labels=[f(x) for x in ticks_x], rotation=45)\n",
        "    plt.yticks([y for y in ticks_y], labels=[f(y) for y in ticks_y])\n",
        "    plt.ylim(0.0001, 0.5)\n",
        "    plt.xlim(0.001, 0.5)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Logical Error Rate (Vertical Observable)\")\n",
        "    plt.xlabel(\"Physical Error Rate Parameter\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def sample_single_depolarizing_layer_circuit():\n",
        "    sample_error_rates(\n",
        "        shots=20000,\n",
        "        probabilities=[\n",
        "            0.001,\n",
        "            0.01,\n",
        "            0.02,\n",
        "            0.03,\n",
        "            0.04,\n",
        "            0.05,\n",
        "            0.06,\n",
        "            0.07,\n",
        "            0.08,\n",
        "            0.09,\n",
        "            0.10,\n",
        "            0.11,\n",
        "            0.12,\n",
        "        ],\n",
        "        before_cycle_1q_depolarization_factor=0,\n",
        "        before_parity_measure_2q_depolarization_factor=0,\n",
        "        before_round_1q_depolarization_factor=0,\n",
        "        noisy_cycles=0,\n",
        "        start_of_all_noisy_cycles_1q_depolarization_factor=1,\n",
        "        diameter_factor=[1, 2, 3],\n",
        "        append=True,\n",
        "        path=\"data.csv\",\n",
        "    )\n",
        "\n",
        "\n",
        "def sample_parity_error_circuit():\n",
        "\n",
        "    sample_error_rates(\n",
        "        shots=10000,\n",
        "        probabilities=[\n",
        "            0.01,\n",
        "            0.015,\n",
        "            0.02,\n",
        "            0.025,\n",
        "            0.03,\n",
        "            0.035,\n",
        "            0.04,\n",
        "            0.045,\n",
        "            0.05,\n",
        "        ],\n",
        "        before_cycle_1q_depolarization_factor=0,\n",
        "        before_parity_measure_2q_depolarization_factor=1,\n",
        "        before_round_1q_depolarization_factor=0,\n",
        "        noisy_cycles=6,\n",
        "        start_of_all_noisy_cycles_1q_depolarization_factor=0,\n",
        "        diameter_factor=[1, 2],\n",
        "        append=True,\n",
        "        path=\"data_from_parity_errors.csv\",\n",
        "    )\n",
        "\n",
        "\n",
        "def main():\n",
        "    # plot_data(\"data_single.csv\",\n",
        "    #           title=\"LogLog error rates for toric circuit with single layer of 1q depolarization\",\n",
        "    #           rounds_per_shot=1)\n",
        "    # return\n",
        "    # sample_single_depolarizing_layer_circuit()\n",
        "\n",
        "    sample_parity_error_circuit()\n",
        "\n",
        "    # plot_data(\"data_from_parity_errors.csv\",\n",
        "    #           title=\"LogLog error rates per round for 6 cycle (18 round) toric no-ancilla circuit with 2q depolarization before parity measurements\",\n",
        "    #           rounds_per_shot=18)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuPGHJGDOHok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}